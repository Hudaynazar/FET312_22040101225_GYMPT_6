{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d8a85d-8521-4b86-af42-8832e7e803ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers accelerate bitsandbytes qwen-vl-utils langchain chromadb sentence-transformers -q\n",
    "!pip install torchvision -q\n",
    "!pip install langchain-community langchain-huggingface chromadb sentence-transformers -q\n",
    "!pip install langchain langchain-core -q\n",
    "!pip install langchain-community -q\n",
    "!pip install --upgrade torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843e123c-caa7-41d3-a4d6-23ec9db7c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor,BitsAndBytesConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a950909e-4574-416c-ae8c-13da0ec1e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çalışma Ortamı: CUDA\n",
      "GPU Modeli: NVIDIA GeForce RTX 4060\n",
      "VRAM Bilgisi: 8.59 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Çalışma Ortamı: {device.upper()}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU Modeli: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM Bilgisi: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"UYARI: CPU kullanıyorsunuz. Model çok yavaş çalışacaktır!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "155d4caf-ea21-4257-b97a-b5c3f590ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cihaz: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d3ba446dea416e9274c5e96f1a82b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Cihaz: {device}\")\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ad9617-e077-4b40-89d6-adea1d420de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nazar\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|██████████| 79.3M/79.3M [01:02<00:00, 1.33MiB/s]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Veritabanı Hazır.\n",
      "2. Model yükleniyor...\n",
      "Cihaz: CUDA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7311e714d9454f9ca7fd79ab159a2280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model Yüklendi.\n",
      "3. Analiz yapılıyor...\n",
      "\n",
      " Veritabanından Bulunan Bilgi:\n",
      "Hamburger: 550 kcal. Orta boy hamburger, yüksek karbonhidrat.\n",
      "Hamburger: 550 kcal. Orta boy hamburger, yüksek karbonhidrat.\n",
      "\n",
      "------------------------------\n",
      "MODELİN CEVABI:\n",
      "Tabakta hamburger, domates, salatalık ve patates tazeği bulunuyor. Hamburgerin kalorisi 550 kcal'dir.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document \n",
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "with open(\"diyet_bilgileri.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    diyet_bilgileri_json = json.load(f)\n",
    "\n",
    "diyet_bilgileri = [f\"{item['food']}: {item['calories']} kcal. {item['description']}\" for item in diyet_bilgileri_json]\n",
    "\n",
    "docs = [Document(page_content=text) for text in diyet_bilgileri]\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=docs, \n",
    "    collection_name=\"kalori_cetveli_v3\"\n",
    ")\n",
    "\n",
    "\n",
    "docs = [Document(page_content=text) for text in diyet_bilgileri]\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=docs, \n",
    "    collection_name=\"kalori_cetveli_v3\"\n",
    ")\n",
    "\n",
    "def bilgi_getir(sorgu):\n",
    "    sonuclar = vector_db.similarity_search(sorgu, k=2)\n",
    "    return \"\\n\".join([doc.page_content for doc in sonuclar])\n",
    "\n",
    "print(\" Veritabanı Hazır.\")\n",
    "\n",
    "print(\"2. Model yükleniyor...\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Cihaz: {device.upper()}\")\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n",
    "\n",
    "print(\" Model Yüklendi.\")\n",
    "\n",
    "print(\"3. Analiz yapılıyor...\")\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/RedDot_Burger.jpg/800px-RedDot_Burger.jpg\"\n",
    "user_question = \"Bu tabakta ne var ve tahmini kalorisi nedir?\"\n",
    "\n",
    "response = requests.get(image_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "rag_context = bilgi_getir(\"hamburger ve patates kalori\") \n",
    "print(f\"\\n Veritabanından Bulunan Bilgi:\\n{rag_context}\\n\")\n",
    "\n",
    "system_prompt = \"\"\"Sen uzman bir diyetisyensin. Görselleri analiz ederken şu adımları izle:\n",
    "1. Tabağı analiz et.\n",
    "2. Veritabanından gelen bilgileri kontrol et.\n",
    "3. Sonucu net bir liste halinde ver.\n",
    "\n",
    "ÖRNEK 1:\n",
    "Kullanıcı Resmi: [Salata Resmi]\n",
    "Context Bilgisi: Sezar salata 400 kalori.\n",
    "Analiz: Tabakta yeşillik ve tavuk var. Soslu görünüyor.\n",
    "Cevap: Tavuklu Sezar Salata (400 kcal). Sos içerdiği için yağ oranı yüksektir.\n",
    "\n",
    "ŞİMDİ SIRA SENDE:\n",
    "\"\"\"\n",
    "\n",
    "final_text_prompt = f\"\"\"\n",
    "{system_prompt}\n",
    "\n",
    "BAĞLAM BİLGİSİ (Veritabanından):\n",
    "{rag_context}\n",
    "\n",
    "SORU:\n",
    "{user_question}\n",
    "\"\"\"\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": final_text_prompt},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "text_prompt = processor.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "inputs = processor(text=[text_prompt], images=[image], return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "output_ids = model.generate(**inputs, max_new_tokens=200)\n",
    "generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"MODELİN CEVABI:\")\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch310)",
   "language": "python",
   "name": "torch310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
